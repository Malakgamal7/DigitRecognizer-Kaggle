{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data sets\n",
    "df_train = pd.read_csv('\\\\Users\\\\malak\\\\Downloads\\\\test\\\\train.csv')\n",
    "df_test = pd.read_csv('\\\\Users\\\\malak\\\\Downloads\\\\test\\\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of missing values per column\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np array of all the target labels (0 to 9)\n",
    "y_train  = df_train['label'].values \n",
    "# drop the labels from training to keep only pixel features \n",
    "# reshape into 4D array (num_rows, height , width , channel)\n",
    "# /255.0 to normalize these pixel values to the range [0, 1] \n",
    "X_train = df_train.drop(columns=['label']).values.reshape(-1,28,28,1)/255.0\n",
    "X_test = df_test.values.reshape(-1, 28, 28, 1) / 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts integer labels into a one-hot encoded formatbinary vector\n",
    "# The length of the vector equals the number of classes\n",
    "# Only the index corresponding to the class is 1, and all other entries are 0\n",
    "y_train_encoded = to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize 10 random images from the training dataset with their labels\n",
    "\n",
    "#2 rows, 5 columns, 12X5 width x height, \n",
    "fig , axes  = plt.subplots(2, 5, figsize=(12,5))\n",
    "\n",
    "#flatten the 2x5 to loop through subplots\n",
    "axes   = axes.flatten()\n",
    "\n",
    "#random select of 10 indexes\n",
    "idx = np.random.randint(0, 42000, size=10)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    #gets image and reshapes\n",
    "    axes[i].imshow(X_train[idx[i], :].reshape(28,28), cmap='gray')\n",
    "    # hide the axes ticks\n",
    "    axes[i].axis('off')\n",
    "    #displays label\n",
    "    axes[i].set_title(str(int(y_train[idx[i]])), color='black', fontsize=25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional Neural Network\n",
    "\n",
    "#Creates a linear stack of layers\n",
    "#layers are added in sequence, from input to output\n",
    "\n",
    "model = models.Sequential([\n",
    "    \n",
    "    #Conv2D: A convolutional layer that applies filters to extract features (edges, textures,...)\n",
    "    #filters=64: Specifies the number of filters (feature detectors) to apply\n",
    "    #kernel_size=3: Sets the size of the filter (3x3)\n",
    "    #padding='same': assure output of the convolution has the same width and height as the input by adding zero-padding\n",
    "    #activation='relu': Rectified Linear Unit (ReLU) activation function (non-linear)\n",
    "    #input_shape=(28,28,1): 28x28 pixels with 1 channel for grayscale\n",
    "    #MaxPool2D: A pooling layer downsamples the spatial dimensions of the feature maps\n",
    "    #Reduces computational complexity and prevent overfitting by making the model invariant to small translations in the input\n",
    "    layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1)),\n",
    "    layers.Conv2D(filters=64, kernel_size=3, padding='same',activation='relu'),\n",
    "    layers.Conv2D(filters=128, kernel_size=3, padding='same',activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=2),\n",
    "    layers.Conv2D(filters=128, kernel_size=3, padding='same',activation='relu'),\n",
    "    layers.Conv2D(filters=192, kernel_size=3, padding='same',activation='relu'),layers.MaxPool2D(pool_size=2),\n",
    "    \n",
    "    #large filter focuses on capturing more global patterns\n",
    "    layers.Conv2D(filters=192, kernel_size=5, padding='same',activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=2, padding='same'),\n",
    "    \n",
    "    #Flatten: Converts the 2D feature maps into a 1D vector, preparing the data for the fully connected (dense) layers\n",
    "    #Necessary to transition from convolutional layers to dense layers\n",
    "    layers.Flatten(),\n",
    "    #Dense: A fully connected layer, 256 neurons, relu activation function\n",
    "    layers.Dense(units=256, activation='relu'),\n",
    "    # Output layer: 10 neurons, one for each class\n",
    "    # softmax: Converts the outputs into a probability distribution over the 10 classes\n",
    "    layers.Dense(units=10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display a detailed summary of the architecture of a neural network model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "\n",
    "#loss='categorical_crossentropy' : loss function used for multi-class classification problems where the target labels are one-hot encoded\n",
    "#calculates the difference between the predicted probability distribution and the true one-hot encoded labels\n",
    "#optimizer='adam': Adam (Adaptive Moment Estimation) optimization algorithm. It adapts the learning rate during training to improve convergence\n",
    "#metrics=['accuracy'] : Tracks the accuracy of the model during training and validation\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Dynamic Learning Rate Adjustment\n",
    "\n",
    "#ReduceLROnPlateau: This is a Keras (TF library) callback that reduces the learning rate when the model's performance stops\n",
    "#monitor='loss': Monitors the training loss to decide when to reduce the learning rate\n",
    "#factor=0.3: Reduces * 0.3\n",
    "#verbose=1: displays message when learning rate is reduced\n",
    "#patience=2: Waits 2 epochs(complete pass through dataset) without improvement in loss before reducing the learning rate\n",
    "#min_lr=0.00000001:lower limit for learning rate\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.3, verbose=1,\n",
    "                              patience=2, min_lr=0.00000001)\n",
    "\n",
    "#Training the Model\n",
    "\n",
    "#model.fit(): Trains the model on the training data\n",
    "#epochs: 25 full passes through dataset\n",
    "#validation_split=0.1: Reserves 10% of the training data for validation\n",
    "#ReduceLROnPlateau callback to adjust the learning rate dynamically based on training performance\n",
    "history = model.fit(\n",
    "    X_train, y_train_encoded, \n",
    "    epochs=25,\n",
    "    validation_split=0.1, \n",
    "    callbacks=[reduce_lr],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Training History to a DataFrame and Plot\n",
    "\n",
    "#history.history: A dictionary containing training metrics recorded during model.fit()\n",
    "#pd.DataFrame: Converts the dictionary into a DataFrame, to visualize\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "#loss: Training loss for each epoch.\n",
    "#val_loss: Validation loss for each epoch.\n",
    "history_frame.loc[: , ['loss', 'val_loss']].plot()\n",
    "#accuracy: Training accuracy for each epoch.\n",
    "#val_accuracy: Validation accuracy for each epoch.\n",
    "history_frame.loc[: , ['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions using test data\n",
    "predictions = model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert probability outputs to digit predictions\n",
    "#Finds the index of the highest probability along the second axis, corresponds to the predicted class label\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Pandas DataFrame to organize the predictions in the required submission format\n",
    "submission = pd.DataFrame({\n",
    "    #assigns an identifier to each image\n",
    "    \"ImageId\": range(1, len(predicted_labels) + 1),\n",
    "    #stores predicted labels\n",
    "    \"Label\": predicted_labels\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# index=False: Prevents Pandas from writing row indices to the file\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
